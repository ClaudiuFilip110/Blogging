{
  
    
        "post0": {
            "title": "Title",
            "content": "This is my first attempt to use Neural Networks. This example is derived from the fast.ai course 1. From what I understand so far these are the steps I need to take in order to build and train a simple model. NOTE: This model uses Transfer learning so this is why it&#39;s accuracy is so high from the beginning. . Steps . imports | take the data from the internet - we are using transfer learning use the bing search API to get the data save the data . | clean the data | create a DataBlock | create a DataLoader | train and fine tune the model | clean the data with ImageClassifierCleaner | see the results with a confusion matrix + some metric besides that | change some parameters to see how you can improve what you&#39;ve done | from fastai import * from utils import * key = &#39;bd1700565fbc42d59a2d3a3732ac9da9&#39; #the API key . #also, create the two folders in which the data will be stored path = Path(&#39;maskclassifier&#39;) if not path.exists(): path.mkdir() #create a path for the mask data dest = (path/&#39;masks&#39;) dest.mkdir(exist_ok=True) results = search_images_bing(key, &#39;person wearing face mask&#39;) download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) #create a path for the non-mask data dest = (path/&#39;non-masks&#39;) dest.mkdir(exist_ok=True) results = search_images_bing(key, &#39;real people faces&#39;) download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) . files = get_image_files(path) failed = verify_images(files) failed #map through the failed ones and remove them using unlink failed.map(Path.unlink) . (#0) [] . data = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)#Transforms performed on every item ) # so now data is a DataBlock . dls = data.dataloaders(path)#data loaders include validation and training dls.valid.show_batch(max_n=4) dls.train.show_batch(max_n=4) . #there seems to be a problem with png files, but that&#39;s not an issues as the error_rate is quite small learn_small = cnn_learner(dls, resnet18, metrics=error_rate) learn_small.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.316123 | 0.478764 | 0.241379 | 00:05 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . epoch train_loss valid_loss error_rate time . 0 | 0.696941 | 0.283659 | 0.086207 | 00:07 | . 1 | 0.481243 | 0.122186 | 0.034483 | 00:06 | . 2 | 0.358144 | 0.110019 | 0.034483 | 00:06 | . 3 | 0.292787 | 0.110305 | 0.034483 | 00:06 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . learn_big = cnn_learner(dls, resnet34, metrics=error_rate) learn_big.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.222488 | 0.599270 | 0.241379 | 00:06 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . epoch train_loss valid_loss error_rate time . 0 | 0.462036 | 0.397535 | 0.137931 | 00:06 | . 1 | 0.353934 | 0.271000 | 0.068965 | 00:07 | . 2 | 0.254554 | 0.243883 | 0.051724 | 00:06 | . 3 | 0.210735 | 0.207723 | 0.051724 | 00:06 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . Differences between resnet18 and resnet34 . As we can see there is a small difference between resnet18 and resnet34 probably because resnet34 is a bigger neural net . small_conf_matrix = ClassificationInterpretation.from_learner(learn_small) small_conf_matrix.plot_confusion_matrix() small_conf_matrix.plot_top_losses(5, nrows=1) big_conf_matrix = ClassificationInterpretation.from_learner(learn_big) big_conf_matrix.plot_confusion_matrix() big_conf_matrix.plot_top_losses(5, nrows=1) . from fastai.vision.widgets import * cleaner = ImageClassifierCleaner(learn) cleaner . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . FileNotFoundError Traceback (most recent call last) &lt;ipython-input-60-53535bf0a65d&gt; in &lt;module&gt; 2 from fastai.vision.widgets import * 3 -&gt; 4 cleaner = ImageClassifierCleaner(learn) 5 cleaner /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/widgets.py in __init__(self, learn, **kwargs) 79 self.dd_cats = Dropdown(options=vocab) 80 self.dd_ds = Dropdown(options=(&#39;Train&#39;,&#39;Valid&#39;)) &gt; 81 self.iwis = _get_iw_info(learn,0),_get_iw_info(learn,1) 82 self.dd_ds.observe(self.on_change_ds, &#39;value&#39;) 83 self.dd_cats.observe(self.on_change_ds, &#39;value&#39;) /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/widgets.py in _get_iw_info(learn, ds_idx) 66 def _get_iw_info(learn, ds_idx=0): 67 dl = learn.dls[ds_idx].new(shuffle=False, drop_last=False) &gt; 68 inp,probs,targs,preds,losses = learn.get_preds(dl=dl, with_input=True, with_loss=True, with_decoded=True) 69 inp,targs = L(zip(*dl.decode_batch((inp,targs), max_n=9999))) 70 return L([dl.dataset.items,targs,losses]).zip() /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in get_preds(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, **kwargs) 233 if with_loss: ctx_mgrs.append(self.loss_not_reduced()) 234 with ContextManagers(ctx_mgrs): --&gt; 235 self._do_epoch_validate(dl=dl) 236 if act is None: act = getattr(self.loss_func, &#39;activation&#39;, noop) 237 res = cb.all_tensors() /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in _do_epoch_validate(self, ds_idx, dl) 186 if dl is None: dl = self.dls[ds_idx] 187 self.dl = dl --&gt; 188 with torch.no_grad(): self._with_events(self.all_batches, &#39;validate&#39;, CancelValidException) 189 190 def _do_epoch(self): /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 153 154 def _with_events(self, f, event_type, ex, final=noop): --&gt; 155 try: self(f&#39;before_{event_type}&#39;) ;f() 156 except ex: self(f&#39;after_cancel_{event_type}&#39;) 157 finally: self(f&#39;after_{event_type}&#39;) ;final() /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in all_batches(self) 159 def all_batches(self): 160 self.n_iter = len(self.dl) --&gt; 161 for o in enumerate(self.dl): self.one_batch(*o) 162 163 def _do_one_batch(self): /opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py in __iter__(self) 100 self.before_iter() 101 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses) --&gt; 102 for b in _loaders[self.fake_l.num_workers==0](self.fake_l): 103 if self.device is not None: b = to_device(b, self.device) 104 yield self.after_batch(b) /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py in __next__(self) 361 362 def __next__(self): --&gt; 363 data = self._next_data() 364 self._num_yielded += 1 365 if self._dataset_kind == _DatasetKind.Iterable and /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py in _next_data(self) 987 else: 988 del self._task_info[idx] --&gt; 989 return self._process_data(data) 990 991 def _try_put_index(self): /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py in _process_data(self, data) 1012 self._try_put_index() 1013 if isinstance(data, ExceptionWrapper): -&gt; 1014 data.reraise() 1015 return data 1016 /opt/conda/envs/fastai/lib/python3.8/site-packages/torch/_utils.py in reraise(self) 393 # (https://bugs.python.org/issue2651), so we work around it. 394 msg = KeyErrorMessage(msg) --&gt; 395 raise self.exc_type(msg) FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0. Original Traceback (most recent call last): File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py&#34;, line 185, in _worker_loop data = fetcher.fetch(index) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py&#34;, line 34, in fetch data = next(self.dataset_iter) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py&#34;, line 111, in create_batches yield from map(self.do_batch, self.chunkify(res)) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/basics.py&#34;, line 198, in chunked res = list(itertools.islice(it, chunk_sz)) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py&#34;, line 124, in do_item try: return self.after_item(self.create_item(s)) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/load.py&#34;, line 130, in create_item def create_item(self, s): return next(self.it) if s is None else self.dataset[s] File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 314, in __getitem__ res = tuple([tl[it] for tl in self.tls]) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 314, in &lt;listcomp&gt; res = tuple([tl[it] for tl in self.tls]) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 280, in __getitem__ return self._after_item(res) if is_indexer(idx) else res.map(self._after_item) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py&#34;, line 242, in _after_item def _after_item(self, o): return self.tfms(o) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 198, in __call__ def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 150, in compose_tfms x = f(x, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 73, in __call__ def __call__(self, x, **kwargs): return self._call(&#39;encodes&#39;, x, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 83, in _call return self._do_call(getattr(self, fn), x, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/transform.py&#34;, line 89, in _do_call return retain_type(f(x, **kwargs), x, ret) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/dispatch.py&#34;, line 129, in __call__ return f(*args, **kwargs) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/core.py&#34;, line 110, in create return cls(load_image(fn, **merge(cls._open_args, kwargs))) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/vision/core.py&#34;, line 85, in load_image im = Image.open(fn) File &#34;/opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py&#34;, line 2878, in open fp = builtins.open(filename, &#34;rb&#34;) FileNotFoundError: [Errno 2] No such file or directory: &#39;/notebooks/fastbook/maskclassifier/masks/00000018.jpg&#39; . for idx in cleaner.delete(): cleaner.fnx[idx].unlink() for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . AttributeError Traceback (most recent call last) &lt;ipython-input-59-187c9c046d77&gt; in &lt;module&gt; 1 #cleaning everything that we changed -&gt; 2 for idx in cleaner.delete(): cleaner.fnx[idx].unlink() 3 for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) /opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in __getattr__(self, k) 133 if self._component_attr_filter(k): 134 attr = getattr(self,self._default,None) --&gt; 135 if attr is not None: return getattr(attr,k) 136 raise AttributeError(k) 137 def __dir__(self): return custom_dir(self,self._dir()) AttributeError: &#39;ImagesCleaner&#39; object has no attribute &#39;fnx&#39; . #we needed to do the training again since some of the training data was missing now learn_small = cnn_learner(dls, resnet18, metrics=error_rate) learn_small.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.398675 | 1.517248 | 0.500000 | 00:06 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . epoch train_loss valid_loss error_rate time . 0 | 0.480259 | 0.518154 | 0.241379 | 00:06 | . 1 | 0.387630 | 0.342573 | 0.120690 | 00:06 | . 2 | 0.302366 | 0.314747 | 0.120690 | 00:07 | . 3 | 0.241848 | 0.307350 | 0.103448 | 00:06 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . these are the best results that we got without the cleaning with the resnet18 0 0.696941 0.283659 0.086207 00:07 1 0.481243 0.122186 0.034483 00:06 2 0.358144 0.110019 0.034483 00:06 3 0.292787 0.110305 0.034483 00:06 . Interestingly enough the results are now worse on the resnet18 0 0.579994 0.314457 0.120690 00:08 1 0.389574 0.321672 0.103448 00:06 2 0.280896 0.403080 0.120690 00:07 3 0.219586 0.405922 0.137931 00:07 . let&#39;s see some metrics . small_conf_matrix = ClassificationInterpretation.from_learner(learn_small) small_conf_matrix.plot_confusion_matrix() small_conf_matrix.plot_top_losses(5, nrows=1) . So, it would seem that I haven&#39;t quite cleaned the data correctly. I will do this at a later time. .",
            "url": "https://claudiufilip110.github.io/Blogging/2020/11/07/first_neural-net.html",
            "relUrl": "/2020/11/07/first_neural-net.html",
            "date": " • Nov 7, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://claudiufilip110.github.io/Blogging/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://claudiufilip110.github.io/Blogging/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}