<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Model from scratch with explanation | Filip Claudiu’s blogs</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Model from scratch with explanation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A MNIST neural network classifier from scratch" />
<meta property="og:description" content="A MNIST neural network classifier from scratch" />
<link rel="canonical" href="https://claudiufilip110.github.io/Blogging/fastpages/jupyter/2020/11/10/model-from-scratch-with-explanation.html" />
<meta property="og:url" content="https://claudiufilip110.github.io/Blogging/fastpages/jupyter/2020/11/10/model-from-scratch-with-explanation.html" />
<meta property="og:site_name" content="Filip Claudiu’s blogs" />
<meta property="og:image" content="https://claudiufilip110.github.io/Blogging/images/model_scratch/model.PNG" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-10T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://claudiufilip110.github.io/Blogging/fastpages/jupyter/2020/11/10/model-from-scratch-with-explanation.html","@type":"BlogPosting","headline":"Model from scratch with explanation","dateModified":"2020-11-10T00:00:00-06:00","datePublished":"2020-11-10T00:00:00-06:00","image":"https://claudiufilip110.github.io/Blogging/images/model_scratch/model.PNG","mainEntityOfPage":{"@type":"WebPage","@id":"https://claudiufilip110.github.io/Blogging/fastpages/jupyter/2020/11/10/model-from-scratch-with-explanation.html"},"description":"A MNIST neural network classifier from scratch","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Blogging/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://claudiufilip110.github.io/Blogging/feed.xml" title="Filip Claudiu's blogs" /><link rel="shortcut icon" type="image/x-icon" href="/Blogging/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Blogging/">Filip Claudiu&#39;s blogs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Blogging/about/">About Me</a><a class="page-link" href="/Blogging/search/">Search</a><a class="page-link" href="/Blogging/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Model from scratch with explanation</h1><p class="page-description">A MNIST neural network classifier from scratch</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-11-10T00:00:00-06:00" itemprop="datePublished">
        Nov 10, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Blogging/categories/#fastpages">fastpages</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Blogging/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/ClaudiuFilip110/Blogging/tree/master/_notebooks/2020-11-10-model-from-scratch-with-explanation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Blogging/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ClaudiuFilip110/Blogging/master?filepath=_notebooks%2F2020-11-10-model-from-scratch-with-explanation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blogging/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ClaudiuFilip110/Blogging/blob/master/_notebooks/2020-11-10-model-from-scratch-with-explanation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blogging/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-11-10-model-from-scratch-with-explanation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this example we will try to code a neural net from the ground up. We will use the basics learned from the earlier examples. Specifically, this model:
<img src="/Blogging/images/copied_from_nb/my_icons/model.PNG" alt="" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Steps">Steps<a class="anchor-link" href="#Steps"> </a></h1><p>The steps we need to take are as follow:</p>
<ol>
<li>init dataset + weights and biases2</li>
<li>calculate gradient <ul>
<li>predict the values</li>
<li>calculate the loss</li>
<li>calc. gradients + go backward</li>
<li>set the gradients to 0 so they don't add up on the next backward pass</li>
</ul>
</li>
<li>calculate the accuracy</li>
</ol>
<h2 id="Requirements">Requirements<a class="anchor-link" href="#Requirements"> </a></h2><ul>
<li>a loss function</li>
<li>a model</li>
<li>scale everything up with fastai libs. and compare</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastbook</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1">#first we need to get the images from the file</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
<span class="n">threes</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;train&#39;</span><span class="o">/</span><span class="s1">&#39;3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span> <span class="c1">#these are paths to the files</span>
<span class="n">sevens</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;train&#39;</span><span class="o">/</span><span class="s1">&#39;7&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>

<span class="c1">#then we put them into tensors</span>
<span class="n">threes_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">threes</span><span class="p">]</span>
<span class="n">sevens_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">sevens</span><span class="p">]</span>
<span class="n">threes_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">4</span><span class="p">:</span><span class="mi">30</span><span class="p">][</span><span class="mi">4</span><span class="p">:</span><span class="mi">30</span><span class="p">],</span> <span class="n">show_image</span><span class="p">(</span><span class="n">threes_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, printing a value from threes_tensors we get a tensor with the value of each pixel. The form resembles a three.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stacked_threes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">threes_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">stacked_sevens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sevens_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">stacked_threes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">],</span> <span class="n">stacked_threes</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">#now we can see the values are scaled between 0 and 1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.9882, 0.9882, 0.8078],
         [0.0000, 0.0000, 0.2471, 0.3686, 0.8510, 0.9922, 0.7412, 0.6196, 0.1373, 0.0784],
         [0.0000, 0.3882, 0.9490, 0.9647, 0.8431, 0.2824, 0.0392, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.9922, 0.9882, 0.5176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.7529, 0.9922, 0.9098, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.3059, 0.9490, 0.9882, 0.9098, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.4039, 0.9451, 0.9882, 0.8706, 0.2235, 0.0431, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.3843, 0.9882, 0.9922, 0.9882, 0.2784, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9922, 0.9098, 0.1843, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3843, 0.7843, 0.9882, 0.9098, 0.0000]]),
 torch.Size([6131, 28, 28]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>the shape is what defins a tensor. We have 6131 images of 28 * 28 height and width. We changed it from an image to a rank 3 tensor. This will provide extremly useful later.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we will be using <b> SGD - stochastic gradient descent </b> to teach the model to learn.</p>
<h2 id="Steps">Steps<a class="anchor-link" href="#Steps"> </a></h2><ol>
<li><em>Initialize</em> the weights.</li>
<li>For each image, use these weights to <em>predict</em> whether it appears to be a 3 or a 7.</li>
<li>Based on these predictions, calculate how good the model is (its <em>loss</em>).</li>
<li>Calculate the <em>gradient</em>, which measures for each weight, how changing that weight would change the loss</li>
<li><em>Step</em> (that is, change) all the weights based on that calculation.</li>
<li>Go back to the step 2, and <em>repeat</em> the process.</li>
<li>Iterate until you decide to <em>stop</em> the training process (for instance, because the model is good enough or you don't want to wait any longer).</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">stacked_threes</span><span class="p">,</span> <span class="n">stacked_sevens</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>


<span class="c1">#we changed the rank of the tensor from 3 to 2 using view.</span>
<span class="c1">#Why? Because it&#39;s easier to work with</span>
<span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([12396, 784]),
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#so the model will predict 1 if it&#39;s a 3 and a 0 if it&#39;s a 7</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">stacked_threes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">stacked_sevens</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#currently we have an array of 1s and 0s that represent all the 3s and 7s in the training set. </span>
<span class="c1">#but we need a 2D array, that&#39;s required from pytorch so we use unsqueeze</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">train_y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([12396])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([12396, 1])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([12396, 784]), torch.Size([12396, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_threes</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;valid&#39;</span><span class="o">/</span><span class="s1">&#39;3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
<span class="n">valid_sevens</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;valid&#39;</span><span class="o">/</span><span class="s1">&#39;7&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
<span class="n">valid_threes_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">valid_threes</span><span class="p">]</span>
<span class="n">valid_sevens_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">valid_sevens</span><span class="p">]</span>

<span class="n">valid_threes_tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">valid_threes_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">valid_sevens_tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">valid_sevens_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>

<span class="n">valid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">valid_threes_tensors</span><span class="p">,</span> <span class="n">valid_sevens_tensors</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">valid_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_threes_tensors</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_sevens_tensors</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">valid_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([2038, 784]), torch.Size([2038, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">valid_dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">))</span>

<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span> <span class="c1"># x -&gt; image, y -&gt; label of that image</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([784]), tensor([1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="c1">#we also need .requires_grad_ so that it knows we want back propagation + we want it in place</span>

<span class="c1">#init. weights</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># we init. a weight for every pixel</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">bias</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># we need this shape later</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([784, 1]), torch.Size([1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have finally finished the first step in our model: initializing the random values which will change in time.</p>
<h1 id="initialize---complete">initialize - complete<a class="anchor-link" href="#initialize---complete"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="predicting">predicting<a class="anchor-link" href="#predicting"> </a></h1><p>The next step is to predict what the value is. How do we do that? We multiply the matrices together. By doing that we get the prediction based on the weights assigned to it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">train_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">bias</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([1.0124], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the predicted value for the first image. But what we need is the prediction for the whole dataset. We can't use for loops(since they are extremly slow, but we can use broadcasting).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">linear1</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span> <span class="k">return</span> <span class="n">xb</span><span class="nd">@weights</span> <span class="o">+</span> <span class="n">bias</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">linear1</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 1.0124],
        [12.9530],
        [ 2.6870],
        ...,
        [13.2774],
        [ 4.4847],
        [ 9.8195]], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see, the first predictions match showing that our math was correct.</p>
<h3 id="So,-we-calculated-the-prediction-using-the-linear-function.">So, we calculated the prediction using the linear function.<a class="anchor-link" href="#So,-we-calculated-the-prediction-using-the-linear-function."> </a></h3><p>The next step is to calculate the loss</p>
<h1 id="Calculating-the-loss">Calculating the loss<a class="anchor-link" href="#Calculating-the-loss"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">==</span> <span class="n">train_y</span>
<span class="n">correct</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1"># this returns the accuracy of the model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.5086318254470825</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we expected, the accuracy of the model is <b> BAD </b>.</p>
<p>AND we can't use the accuracy of the model as the loss functions since a small change in the weights will, most likely, not change the accuracy, so we need another loss function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">mnist_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">predictions</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">mnist_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.4906861484050751</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Of course, the loss function is 1 - the accuracy. Now that we have finished the loss step of the road, the next thing we need to do is <b> optimization </b>.</p>
<h1 id="Optimization">Optimization<a class="anchor-link" href="#Optimization"> </a></h1><p>In order to optimize we use batches. What are batches?</p>
<p><b> Batches </b> are chunks of data. We could train the model for the whole dataset, but it would take a lot of time. And we could also train the model on a single piece of data train_x[0], but that will not produce very  accurate results. So, by having this compromise we can take "the good" from both methods.</p>
<p>DataLoader already has a batch_size parameter. That being said, we can start implementing everything up until now in a more concise way.</p>
<h2 id="Putting-it-all-together">Putting it all together<a class="anchor-link" href="#Putting-it-all-together"> </a></h2><ul>
<li>init parameters</li>
<li>init dataLoader: dset + batch_size</li>
<li>create a func. that does prediction, loss and gradient for us</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#dataloader</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1">#why LOSS.backward()? because we need to calculate loss&#39;(train_x). That is the gradient</span>

<span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">first</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
<span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">linear1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(-0.0093) tensor([-0.0705])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([0.])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span><span class="n">yb</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            
<span class="c1">#now we need a function to tell us the accuracy of the model</span>
<span class="c1"># xb is actually model(xb)</span>
<span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="n">corrects</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">yb</span>
    <span class="k">return</span> <span class="n">corrects</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>


<span class="c1">#now let&#39;s try to train for an epoch and see if there is any change</span>
<span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">bias</span>
<span class="nb">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">))</span>
<span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.5101)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.6547)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can clearly see that the improvement is massive. Clearly, we are going in the right direction. I'm wondering what would happen if we added the learning rate, instead of subtracting it. So let's try.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch_plus</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span><span class="n">yb</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            

<span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">bias</span>
<span class="nb">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">))</span>
<span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.6547)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.8661)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Apparently there is no difference. That's good to know. Continuing and creating a loop we can train a model for however many epochs we desire.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1.0</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">bias</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.9257)
tensor(0.9462)
tensor(0.9540)
tensor(0.9599)
tensor(0.9628)
tensor(0.9642)
tensor(0.9662)
tensor(0.9691)
tensor(0.9706)
tensor(0.9716)
tensor(0.9716)
tensor(0.9726)
tensor(0.9721)
tensor(0.9726)
tensor(0.9736)
tensor(0.9736)
tensor(0.9740)
tensor(0.9745)
tensor(0.9755)
tensor(0.9755)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, we have created a model from scratch complete with a loss function, an activation function, gradient descent and everything else. Everything we created thus far has been in order to appreciate how simple models really are. PyTorch already has these functionalities, so going furthur we will use theirs instead of ours( since theirs are more optimised).</p>
<h1 id="Optimizer">Optimizer<a class="anchor-link" href="#Optimizer"> </a></h1><p>We can start using PyTorch's methods. For example:</p>
<p>nn.Linear does exactly what our init_params + linear1 does, but better. Using this information we can create our own BasicOptimizer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">linear_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([1, 784]), torch.Size([1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">BasicOptim</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="p">,</span><span class="n">lr</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">),</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1">#again, this optimizer is just for learning purposes.</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">BasicOptim</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="p">)</span>
<span class="c1">#thus making our train_epoch loop clearer and more concise</span>
<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># does the learning</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_model</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.4932)
tensor(0.7041)
tensor(0.8647)
tensor(0.9194)
tensor(0.9375)
tensor(0.9541)
tensor(0.9619)
tensor(0.9663)
tensor(0.9672)
tensor(0.9687)
tensor(0.9712)
tensor(0.9716)
tensor(0.9731)
tensor(0.9745)
tensor(0.9750)
tensor(0.9770)
tensor(0.9770)
tensor(0.9775)
tensor(0.9785)
tensor(0.9785)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="conclusions-thus-far">conclusions thus far<a class="anchor-link" href="#conclusions-thus-far"> </a></h1><p>We have managed to create a model from the ground up. We created our own loss function, our own linear function, which we later swapped for a nn.Linear from the pyTorch library and the model from scratch; complete with batch sizes, epoch training and full model training. Finally, we created a simple optimizer for our model.</p>
<p>This was so we can get accustomed to the way these models work. I hope I understood them correctly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">linear_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="p">)</span>
<span class="n">train_model</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(0.4932)
tensor(0.6846)
tensor(0.8725)
tensor(0.9199)
tensor(0.9379)
tensor(0.9516)
tensor(0.9619)
tensor(0.9658)
tensor(0.9668)
tensor(0.9692)
tensor(0.9712)
tensor(0.9716)
tensor(0.9731)
tensor(0.9751)
tensor(0.9750)
tensor(0.9765)
tensor(0.9770)
tensor(0.9775)
tensor(0.9785)
tensor(0.9789)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Everything we've learned so far can be summed up in these 3 lines of code. We did this so we can understand that ML and NN are not a black box, just a tad complex, but with patience and a little determination we can understand them. Continuing in using the functionalities of fastai and pyTorch we can simplify this even further</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span> <span class="c1"># this will contain all our datasets</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>
<span class="c1">#now we .fit so the model can learn</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>batch_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.635360</td>
      <td>0.494356</td>
      <td>0.495584</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.226966</td>
      <td>0.318078</td>
      <td>0.676153</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.093637</td>
      <td>0.142499</td>
      <td>0.871933</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.047846</td>
      <td>0.093609</td>
      <td>0.921001</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.030696</td>
      <td>0.070695</td>
      <td>0.937684</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.023929</td>
      <td>0.057301</td>
      <td>0.953876</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.021051</td>
      <td>0.048755</td>
      <td>0.963199</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.019648</td>
      <td>0.043098</td>
      <td>0.965653</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.018820</td>
      <td>0.039178</td>
      <td>0.967125</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.018225</td>
      <td>0.036301</td>
      <td>0.969087</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.017732</td>
      <td>0.034072</td>
      <td>0.971050</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.017297</td>
      <td>0.032270</td>
      <td>0.971541</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.016904</td>
      <td>0.030767</td>
      <td>0.973013</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.016548</td>
      <td>0.029488</td>
      <td>0.974485</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.016226</td>
      <td>0.028387</td>
      <td>0.975466</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.015936</td>
      <td>0.027430</td>
      <td>0.976938</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.015675</td>
      <td>0.026594</td>
      <td>0.976938</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.015439</td>
      <td>0.025859</td>
      <td>0.977429</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.015227</td>
      <td>0.025209</td>
      <td>0.977920</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.015035</td>
      <td>0.024630</td>
      <td>0.978410</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="WOW">WOW<a class="anchor-link" href="#WOW"> </a></h1><p>In the end, all these libraries do is what we already know how to do. but we applied our knowledge on linear functions up until now.</p>
<p>In order to be called Neural Networks we need a non-linear model so it can fit anything that is not linear. You'd think this would be the hardest step this far, but it is actually the easiest of them all because we have learnt so much beforehand. pyTorch helps us in that regard.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w1</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">))</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">w2</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">simple_net</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">xb</span><span class="nd">@w1</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="nd">@w2</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="non-linearity">non linearity<a class="anchor-link" href="#non-linearity"> </a></h1><p>We have just created a simple neural network. It is non-linear because we have the <code>res = res.max(tensor(0.0))</code> which is a ReLU - rectified liniar unit.
The weights shape must align
<code>w1</code> has 30 output activations which means <code>w2</code> must have 30 input activations and 1 output, which is (of course) the result we want.</p>
<p>ReLU sounds complicated, but all it does is replace every negative value with 0 and leaves the positive values alone.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_function</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">simple_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All <code>nn.Sequential</code> does is create a model so we can call each layer in turn. Now let's convert the linear model to a neural network model and give it a smaller learning rate( since this is a deeper model).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">simple_net</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>
<span class="c1">#everything except the SGD is &#39;home made&#39;</span>
<span class="n">learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>batch_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.317200</td>
      <td>0.411041</td>
      <td>0.504907</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.144616</td>
      <td>0.221571</td>
      <td>0.813543</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.079456</td>
      <td>0.109266</td>
      <td>0.922964</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.052203</td>
      <td>0.074251</td>
      <td>0.943081</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.039732</td>
      <td>0.058410</td>
      <td>0.959274</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.033423</td>
      <td>0.049514</td>
      <td>0.965653</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.029829</td>
      <td>0.043923</td>
      <td>0.966634</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.027523</td>
      <td>0.040106</td>
      <td>0.968106</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.025874</td>
      <td>0.037340</td>
      <td>0.969578</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.024594</td>
      <td>0.035239</td>
      <td>0.970559</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.023543</td>
      <td>0.033573</td>
      <td>0.974485</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.022650</td>
      <td>0.032207</td>
      <td>0.974975</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.021876</td>
      <td>0.031052</td>
      <td>0.975466</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.021193</td>
      <td>0.030056</td>
      <td>0.975957</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.020586</td>
      <td>0.029181</td>
      <td>0.975957</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.020041</td>
      <td>0.028401</td>
      <td>0.975957</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.019550</td>
      <td>0.027696</td>
      <td>0.976938</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.019103</td>
      <td>0.027055</td>
      <td>0.977429</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.018695</td>
      <td>0.026469</td>
      <td>0.977429</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.018321</td>
      <td>0.025932</td>
      <td>0.978410</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.017976</td>
      <td>0.025435</td>
      <td>0.978901</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.017658</td>
      <td>0.024976</td>
      <td>0.978901</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.017363</td>
      <td>0.024549</td>
      <td>0.979392</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.017089</td>
      <td>0.024152</td>
      <td>0.979392</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.016833</td>
      <td>0.023783</td>
      <td>0.980373</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.016595</td>
      <td>0.023437</td>
      <td>0.980864</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.016371</td>
      <td>0.023114</td>
      <td>0.980864</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.016162</td>
      <td>0.022812</td>
      <td>0.981354</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.015965</td>
      <td>0.022529</td>
      <td>0.981845</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.015779</td>
      <td>0.022264</td>
      <td>0.981845</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.015603</td>
      <td>0.022015</td>
      <td>0.982826</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>31</td>
      <td>0.015437</td>
      <td>0.021780</td>
      <td>0.982826</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>32</td>
      <td>0.015278</td>
      <td>0.021559</td>
      <td>0.982826</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>33</td>
      <td>0.015127</td>
      <td>0.021351</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.014983</td>
      <td>0.021154</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>35</td>
      <td>0.014846</td>
      <td>0.020967</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>36</td>
      <td>0.014715</td>
      <td>0.020789</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.014589</td>
      <td>0.020620</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>38</td>
      <td>0.014468</td>
      <td>0.020458</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.014352</td>
      <td>0.020303</td>
      <td>0.983808</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">L</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">itemgot</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;final accuracy </span><span class="si">{</span><span class="n">learner</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>final accuracy 0.9838076829910278
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we can see the learning rate of the model. It's quite exponential and it is actually to be expected. Of course, on different datasets( when we go for the whole MNIST dataset) it will be different. But we'll pass that hurdle when we get there.</p>
<h1 id="Final-thoughts">Final thoughts<a class="anchor-link" href="#Final-thoughts"> </a></h1><p>we've coded a neural model from scratch. I believe we've understood some fundamentally important aspects of model processing, Machine Learning and Neural Networks. The accuracy of the model is quite high for just 1-2 minutes of training AND this is a base and simple model. Using techniques that we can learn later on we'll improve these 'rookie' numbers. I look forward to that.</p>
<p>To finish things off here is some jargon used daily in the ML world:</p>
<ul>
<li>ReLU - an activation function that sets negative values to 0 and leaves positive ones untouched</li>
<li>activation function - a function that decides when a neuron should be activated /started</li>
<li>mini-batch - a batch is a small collection of the data(ex. 256 items)</li>
<li>forward pass - calculating the activation functions and loss for the layer</li>
<li>loss - a metric used by the computer to calculate how accurate our model is</li>
<li>gradient - the derivation of the loss function. This is used in the backward pass</li>
<li>backward pass - calculating the gradient and changing the values of the parameters( weights and biases).. also called a step</li>
<li>learning rate - the rate at which the system will learn.. higher values will make the model learn faster, but it is more prone to error and <code>bouncing</code>.. too small a value and you will never learn fast enough so the learning rate is a pretty important aspect of the model</li>
</ul>
<p>I've added the graph that shows how the model learns. I cannot stress this enough, this is not a black box if you understand the concepts behind it.</p>
<p><img src="/Blogging/images/copied_from_nb/my_icons/title.PNG" alt="" /></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ClaudiuFilip110/Blogging"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Blogging/fastpages/jupyter/2020/11/10/model-from-scratch-with-explanation.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Blogging/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Blogging/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Blogging/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blogging platform built using fastai&#39;s fastblog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/ClaudiuFilip110" title="ClaudiuFilip110"><svg class="svg-icon grey"><use xlink:href="/Blogging/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/claudiu-filip-1394a7190%2F" title="claudiu-filip-1394a7190/"><svg class="svg-icon grey"><use xlink:href="/Blogging/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
